{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "698326da",
   "metadata": {},
   "source": [
    "# B.1 - Preprocessing, Network Construction, and Language Detection\n",
    "\n",
    "## Necessary Input Files:\n",
    "- `goals_with_attributes.json`: Complete goals data with titles, descriptions, and metadata\n",
    "- `users_with_goals.json`: User-goal relationships showing which goals each user has included\n",
    "- `../02_preprocessing/lid.176.bin`: fastText language detection model (for Part II)\n",
    "\n",
    "## Workflow:\n",
    "\n",
    "### Part I: Network Construction (Sections 1-9)\n",
    "1. **Load and Filter Data**: Load goal and user data, filter goals to only those with valid descriptions\n",
    "2. **Create Co-occurrence Network**: Build initial network where goals are connected if they appear in the same user's list\n",
    "3. **Show Sample Goals**: Display examples of goals with/without descriptions\n",
    "4. **Prepare Text for Embedding**: Combine title and description for ALL goals\n",
    "5. **Compute Embeddings**: Use sentence transformers to create embeddings (saves to `goal_embeddings.npy` for reuse)\n",
    "6. **Find Similar Goals**: Use cosine similarity threshold (0.9) to group similar goals via Union-Find algorithm\n",
    "7. **Analyze Similar Groups**: Show statistics and examples of all groups found\n",
    "8. **Export Mapping**: Create Excel file with goal-to-representative mappings for validation\n",
    "9. **Create Filtered Network**: Rebuild network using only representative goals and export to pickle file\n",
    "\n",
    "### Part II: Network and Language Inspection\n",
    "This section can run independently by loading the saved network file:\n",
    "- **Load Network**: Read the filtered network from pickle file\n",
    "- **Inspect Network**: Show connected components statistics\n",
    "- **Language Detection (Section 10)**: Use fastText to detect language of each goal and export to Excel\n",
    "\n",
    "## Output Files:\n",
    "- `goal_embeddings.npy`: Cached sentence embeddings for all goals\n",
    "- `goal_embedding_ids.json`: Goal IDs corresponding to the embeddings\n",
    "- `goal_mapping_validation.xlsx`: Excel file with three sheets:\n",
    "  - 'Goal Mapping': All goals in groups with their representatives\n",
    "  - 'Summary': Overview statistics of the merging process\n",
    "  - 'Representatives': Final list of representative goals\n",
    "- `filtered_network.pkl`: NetworkX graph with merged goals (representative nodes only)\n",
    "- `filtered_network_nodes.xlsx`: Node attributes including language detection results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdfdc97",
   "metadata": {},
   "source": [
    "After running this notebook for the first time, we had our embeddings data to skip the long process when running the notebook again. However, due to the files being too large to store on github, this notebook needs to compute the embeddings all over again if you want to run it. Similarly, for the language detection part, we are using the fastText language detection model, which was downloaded prior, and could also not be stored on github. You can orientate on the current output or download the lid.176.bin model yourself on: https://fasttext.cc/docs/en/language-identification.html."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316b8b47",
   "metadata": {},
   "source": [
    "## 1. Setup and Load Data\n",
    "Import necessary libraries and load the input JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b65aa97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Besitzer\\Desktop\\M.Sc. Social Data Science\\3. Semester\\Social graphs and interactions\\DayZero\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import os\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "471ca463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 231,269 goals\n",
      "Loaded 10,087 users\n",
      "\n",
      "Sample Goal (ID: jE2QgdsE):\n",
      "  Title: Try Geocaching\n",
      "  Description: (empty)...\n",
      "  Wants to do: 579\n",
      "  Have done: 156\n",
      "  Comments: 12 comments\n",
      "  Tags: 35 tags\n",
      "\n",
      "Sample User (spockaholic):\n",
      "  Number of goals: 86\n",
      "  First goal: {'id': 'jE2QgdsE', 'href': '/goal/jE2QgdsE', 'text': 'Try Geocaching'}\n",
      "\n",
      "Goals with valid descriptions: 3,394 (1.5%)\n",
      "Goals without valid descriptions: 227,875 (98.5%)\n"
     ]
    }
   ],
   "source": [
    "# Load data files\n",
    "with open('../Data/goals_with_attributes.json', 'r', encoding='utf-8') as f:\n",
    "    goals = json.load(f)\n",
    "print(f\"Loaded {len(goals):,} goals\")\n",
    "\n",
    "with open('../Data/users_with_goals.json', 'r', encoding='utf-8') as f:\n",
    "    users_data = json.load(f)\n",
    "print(f\"Loaded {len(users_data):,} users\")\n",
    "\n",
    "# Explore data structure\n",
    "sample_goal_id = list(goals.keys())[0]\n",
    "print(f\"\\nSample Goal (ID: {sample_goal_id}):\")\n",
    "print(f\"  Title: {goals[sample_goal_id]['title']}\")\n",
    "print(f\"  Description: {goals[sample_goal_id]['description'][:100] if goals[sample_goal_id]['description'] else '(empty)'}...\")\n",
    "print(f\"  Wants to do: {goals[sample_goal_id]['wants_to_do']}\")\n",
    "print(f\"  Have done: {goals[sample_goal_id]['have_done']}\")\n",
    "print(f\"  Comments: {len(goals[sample_goal_id]['comments'])} comments\")\n",
    "print(f\"  Tags: {len(goals[sample_goal_id]['tags'])} tags\")\n",
    "\n",
    "sample_user = list(users_data.keys())[0]\n",
    "print(f\"\\nSample User ({sample_user}):\")\n",
    "print(f\"  Number of goals: {len(users_data[sample_user])}\")\n",
    "print(f\"  First goal: {users_data[sample_user][0]}\")\n",
    "\n",
    "# Filter goals with valid descriptions NOW (before network creation)\n",
    "goals_with_descriptions = {}\n",
    "for gid, gdata in goals.items():\n",
    "    desc = gdata.get('description', '')\n",
    "    if desc.strip():  # Non-empty after stripping whitespace\n",
    "        goals_with_descriptions[gid] = gdata\n",
    "\n",
    "print(f\"\\nGoals with valid descriptions: {len(goals_with_descriptions):,} ({100*len(goals_with_descriptions)/len(goals):.1f}%)\")\n",
    "print(f\"Goals without valid descriptions: {len(goals) - len(goals_with_descriptions):,} ({100*(len(goals)-len(goals_with_descriptions))/len(goals):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4740c6",
   "metadata": {},
   "source": [
    "## 2. Create Initial Co-occurrence Network\n",
    "Build network where goals are connected if they co-occur in a user's list (only includes goals with valid descriptions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "648b2460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial network statistics:\n",
      "  Nodes (goals): 3,394\n",
      "  Edges: 258,027\n",
      "  Max possible edges: 5,757,921\n",
      "  Network density: 0.04481253\n",
      "  Average degree: 152.05\n",
      "\n",
      "  Connected components: 32\n",
      "  Largest component size: 3,359 nodes (99.0%)\n"
     ]
    }
   ],
   "source": [
    "# Build co-occurrence network (only goals with descriptions)\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add only goals with descriptions as nodes (with all attributes)\n",
    "for gid, gdata in goals_with_descriptions.items():\n",
    "    G.add_node(gid, \n",
    "               title=gdata['title'],\n",
    "               description=gdata['description'],\n",
    "               wants_to_do=gdata['wants_to_do'],\n",
    "               have_done=gdata['have_done'],\n",
    "               comments=gdata['comments'],\n",
    "               tags=gdata['tags'])\n",
    "\n",
    "# Build edges from co-occurrences\n",
    "edge_counter = Counter()\n",
    "\n",
    "for username, goals_list in users_data.items():\n",
    "    # Extract goal IDs that have descriptions\n",
    "    user_goal_ids = [item['id'] for item in goals_list \n",
    "                     if 'id' in item and item['id'] in goals_with_descriptions]\n",
    "    \n",
    "    # Create edges between all pairs\n",
    "    for i, goal_i in enumerate(user_goal_ids):\n",
    "        for goal_j in user_goal_ids[i+1:]:\n",
    "            edge = tuple(sorted([goal_i, goal_j]))\n",
    "            edge_counter[edge] += 1\n",
    "\n",
    "# Add edges to graph (with weights = co-occurrence count)\n",
    "for (g1, g2), weight in edge_counter.items():\n",
    "    G.add_edge(g1, g2, weight=weight)\n",
    "\n",
    "# Calculate network statistics\n",
    "num_nodes = G.number_of_nodes()\n",
    "num_edges = G.number_of_edges()\n",
    "max_possible_edges = (num_nodes * (num_nodes - 1)) // 2\n",
    "density = nx.density(G)\n",
    "\n",
    "print(\"\\nInitial network statistics:\")\n",
    "print(f\"  Nodes (goals): {num_nodes:,}\")\n",
    "print(f\"  Edges: {num_edges:,}\")\n",
    "print(f\"  Max possible edges: {max_possible_edges:,}\")\n",
    "print(f\"  Network density: {density:.8f}\")\n",
    "print(f\"  Average degree: {2*num_edges/num_nodes:.2f}\")\n",
    "\n",
    "# Connected components\n",
    "num_components = nx.number_connected_components(G)\n",
    "largest_cc = max(nx.connected_components(G), key=len) if num_components > 0 else set()\n",
    "print(f\"\\n  Connected components: {num_components:,}\")\n",
    "print(f\"  Largest component size: {len(largest_cc):,} nodes ({100*len(largest_cc)/num_nodes:.1f}%)\")\n",
    "\n",
    "# Store for later comparison\n",
    "original_num_nodes = num_nodes\n",
    "original_num_edges = num_edges\n",
    "original_density = density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72f8892",
   "metadata": {},
   "source": [
    "## 3. Show Sample Goals\n",
    "Display examples of goals with and without valid descriptions to understand what's included/excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f78b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample goals with valid descriptions (used in initial network):\n",
      "\n",
      "1. Make ice cream from scratch\n",
      "   Description: Ice cream or ice-cream is a frozen dessert usually made from dairy products, such as milk and cream, and often combined with fruits or other ingredien...\n",
      "   Stats: 3010 want to do, 973 have done, 46 comments\n",
      "\n",
      "2. Leave an inspirational note inside a book for someone to find\n",
      "   Description: Imagine the joy of discovering a heartfelt message nestled within the pages of a book, a simple yet profound gesture that can brighten someone's day o...\n",
      "   Stats: 9856 want to do, 966 have done, 56 comments\n",
      "\n",
      "3. Fly a kite\n",
      "   Description: A kite is a tethered heavier-than-air or lighter-than-air craft with wing surfaces that react against the air to create lift and drag forces. A kite c...\n",
      "   Stats: 3030 want to do, 1199 have done, 37 comments\n",
      "\n",
      "4. Go skydiving\n",
      "   Description: Parachuting, including also skydiving, is a method of transiting from a high point in the atmosphere to the surface of Earth with the aid of gravity, ...\n",
      "   Stats: 5318 want to do, 618 have done, 43 comments\n",
      "\n",
      "5. Visit the Library of Congress\n",
      "   Description: The Library of Congress is the research library of the United States Congress, de facto national library of the United States, and the oldest federal ...\n",
      "   Stats: 69 want to do, 66 have done, 1 comments\n",
      "\n",
      "Sample goals without valid descriptions:\n",
      "\n",
      "1. Try Geocaching\n",
      "   Description: ''\n",
      "   Stats: 579 want to do, 156 have done\n",
      "\n",
      "2. Send a secret to PostSecret\n",
      "   Description: ''\n",
      "   Stats: 3990 want to do, 329 have done\n",
      "\n",
      "3. run a 10k\n",
      "   Description: ''\n",
      "   Stats: 78 want to do, 11 have done\n",
      "\n",
      "4. Go Rollerskating\n",
      "   Description: ''\n",
      "   Stats: 46 want to do, 47 have done\n",
      "\n",
      "5. Learn to play the guitar\n",
      "   Description: ''\n",
      "   Stats: 1711 want to do, 139 have done\n"
     ]
    }
   ],
   "source": [
    "# Show examples of filtered goals\n",
    "print(\"\\nSample goals with valid descriptions (used in initial network):\")\n",
    "for i, (gid, gdata) in enumerate(list(goals_with_descriptions.items())[:5], 1):\n",
    "    print(f\"\\n{i}. {gdata['title']}\")\n",
    "    desc = gdata['description']\n",
    "    print(f\"   Description: {desc[:150]}...\")\n",
    "    print(f\"   Stats: {gdata['wants_to_do']} want to do, {gdata['have_done']} have done, {len(gdata['comments'])} comments\")\n",
    "\n",
    "print(\"\\nSample goals without valid descriptions:\")\n",
    "goals_without_desc = {k: v for k, v in goals.items() if k not in goals_with_descriptions}\n",
    "for i, (gid, gdata) in enumerate(list(goals_without_desc.items())[:5], 1):\n",
    "    desc = gdata.get('description', '')\n",
    "    print(f\"\\n{i}. {gdata['title']}\")\n",
    "    print(f\"   Description: '{desc}'\")\n",
    "    print(f\"   Stats: {gdata['wants_to_do']} want to do, {gdata['have_done']} have done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb66968",
   "metadata": {},
   "source": [
    "## 4. Prepare Text for ALL Goals (for Similarity Analysis)\n",
    "For similarity mapping, use all goals: title+description if valid, or title+\"\" if not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8e3c83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 231,269 texts for embedding (ALL goals)\n",
      "  - 3,394 with valid descriptions\n",
      "  - 227,875 with only title (no valid description)\n",
      "\n",
      "Text length statistics:\n",
      "  Mean: 39 characters\n",
      "  Median: 29 characters\n",
      "  Max: 2,317 characters\n",
      "  Min: 1 characters\n"
     ]
    }
   ],
   "source": [
    "# Prepare text for embedding - USE ALL GOALS\n",
    "goal_ids_for_embedding = list(goals.keys())  # ALL goals, not just with descriptions\n",
    "goal_combined_texts = []\n",
    "\n",
    "for gid in goal_ids_for_embedding:\n",
    "    title = goals[gid]['title']\n",
    "    desc = goals[gid].get('description', '')\n",
    "    \n",
    "    # Check if description is valid (non-empty after stripping)\n",
    "    description = desc.strip()\n",
    "    \n",
    "    # Combine title and description\n",
    "    combined = f\"{title}. {description}\" if description else title\n",
    "    goal_combined_texts.append(combined.strip())\n",
    "\n",
    "print(f\"Prepared {len(goal_combined_texts):,} texts for embedding (ALL goals)\")\n",
    "print(f\"  - {len(goals_with_descriptions):,} with valid descriptions\")\n",
    "print(f\"  - {len(goals) - len(goals_with_descriptions):,} with only title (no valid description)\")\n",
    "\n",
    "# Text statistics\n",
    "text_lengths = [len(t) for t in goal_combined_texts]\n",
    "print(f\"\\nText length statistics:\")\n",
    "print(f\"  Mean: {np.mean(text_lengths):.0f} characters\")\n",
    "print(f\"  Median: {np.median(text_lengths):.0f} characters\")\n",
    "print(f\"  Max: {np.max(text_lengths):,} characters\")\n",
    "print(f\"  Min: {np.min(text_lengths):,} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160e1658",
   "metadata": {},
   "source": [
    "## 5. Create Embeddings using Sentence Transformer\n",
    "Load pre-trained model and generate embeddings for all goal texts. (Note that the displayed output of this cell contains the output logic for when the embeddings were already created, such that we do not have to run it again each time we run through this notebook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e76c86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading existing embeddings from ../Data/Embeddings, Similarity and Language Detection/goal_embeddings.npy...\n",
      "Loaded embeddings for 231,269 goals\n",
      "  Shape: (231269, 384)\n",
      "  Embedding dimension: 384\n",
      "\n",
      "Sample embedding for first goal:\n",
      "  Goal: Try Geocaching...\n",
      "  Embedding (first 10 dims): [ 0.00925845 -0.0417789  -0.02357222 -0.04139975  0.0457349  -0.10426646\n",
      " -0.06940327 -0.07827378 -0.04529943  0.03908972]\n",
      "  L2 norm: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Load sentence transformer model and create embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Fast and efficient model\n",
    "\n",
    "# Check if embeddings already exist (to save time on reruns)\n",
    "embeddings_file = '../Data/Embeddings, Similarity and Language Detection/goal_embeddings.npy'\n",
    "embedding_ids_file = '../Data/Embeddings, Similarity and Language Detection/goal_embedding_ids.json'\n",
    "\n",
    "if os.path.exists(embeddings_file) and os.path.exists(embedding_ids_file):\n",
    "    print(f\"\\nLoading existing embeddings from {embeddings_file}...\")\n",
    "    embeddings = np.load(embeddings_file)\n",
    "    \n",
    "    with open(embedding_ids_file, 'r', encoding='utf-8') as f:\n",
    "        saved_goal_ids = json.load(f)\n",
    "    \n",
    "    # Verify that saved IDs match current goal_ids_for_embedding\n",
    "    if saved_goal_ids == goal_ids_for_embedding:\n",
    "        print(f\"Loaded embeddings for {len(embeddings):,} goals\")\n",
    "        print(f\"  Shape: {embeddings.shape}\")\n",
    "        print(f\"  Embedding dimension: {embeddings.shape[1]}\")\n",
    "    else:\n",
    "        print(\"Warning: Saved embeddings don't match current goals. Recomputing...\")\n",
    "        embeddings = model.encode(goal_combined_texts, show_progress_bar=True, batch_size=32)\n",
    "        np.save(embeddings_file, embeddings)\n",
    "        with open(embedding_ids_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(goal_ids_for_embedding, f)\n",
    "        print(f\"Created and saved embeddings for {len(embeddings):,} goals\")\n",
    "else:\n",
    "    print(f\"\\nCreating embeddings for {len(goal_combined_texts):,} goal texts...\")\n",
    "    print(\"(This may take a few minutes...)\")\n",
    "    embeddings = model.encode(goal_combined_texts, show_progress_bar=True, batch_size=32)\n",
    "    \n",
    "    # Save embeddings for future use\n",
    "    print(f\"\\nSaving embeddings to {embeddings_file}...\")\n",
    "    np.save(embeddings_file, embeddings)\n",
    "    \n",
    "    with open(embedding_ids_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(goal_ids_for_embedding, f)\n",
    "    \n",
    "    print(f\"Created and saved embeddings for {len(embeddings):,} goals\")\n",
    "    print(f\"  Shape: {embeddings.shape}\")\n",
    "    print(f\"  Embedding dimension: {embeddings.shape[1]}\")\n",
    "\n",
    "# Show sample embeddings\n",
    "print(f\"\\nSample embedding for first goal:\")\n",
    "print(f\"  Goal: {goal_combined_texts[0][:80]}...\")\n",
    "print(f\"  Embedding (first 10 dims): {embeddings[0][:10]}\")\n",
    "print(f\"  L2 norm: {np.linalg.norm(embeddings[0]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71e0c17",
   "metadata": {},
   "source": [
    "## 6. Find Similar Goals using Cosine Similarity\n",
    "Group goals that exceed similarity threshold and select most popular goal as representative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34f9cf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting goal popularity (included_by_our_users)...\n",
      "Goal popularity statistics:\n",
      "  Mean: 2.2\n",
      "  Median: 1\n",
      "  Max: 1,672\n",
      "  Min: 1\n",
      "\n",
      "Note: Computing full similarity matrix (231,269 x 231,269) would require ~199 GB\n",
      "Instead, we'll compute similarities in batches and find groups incrementally...\n"
     ]
    }
   ],
   "source": [
    "# Count popularity first (needed for representative selection)\n",
    "print(\"Counting goal popularity (included_by_our_users)...\")\n",
    "included_by_our_users = Counter()\n",
    "for username, goals_list in users_data.items():\n",
    "    for item in goals_list:\n",
    "        if 'id' in item:\n",
    "            included_by_our_users[item['id']] += 1\n",
    "\n",
    "print(f\"Goal popularity statistics:\")\n",
    "pop_values = list(included_by_our_users.values())\n",
    "print(f\"  Mean: {np.mean(pop_values):.1f}\")\n",
    "print(f\"  Median: {np.median(pop_values):.0f}\")\n",
    "print(f\"  Max: {max(pop_values):,}\")\n",
    "print(f\"  Min: {min(pop_values):,}\")\n",
    "\n",
    "print(f\"\\nNote: Computing full similarity matrix ({len(embeddings):,} x {len(embeddings):,}) would require ~199 GB\")\n",
    "print(\"Instead, we'll compute similarities in batches and find groups incrementally...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc0e42cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading existing similarity results from ../Data/Embeddings, Similarity and Language Detection/similarity_results_cache.pkl...\n",
      "Loaded similarity results (threshold = 0.9)\n",
      "\n",
      "Loaded 283 groups of similar goals\n",
      "\n",
      "Group statistics:\n",
      "  Total goals in groups: 866\n",
      "  Goals with descriptions in groups: 787\n",
      "  Groups (representatives): 283\n",
      "  Goals merged: 583\n",
      "  Reduction: 583 goals (0.3% of all goals)\n"
     ]
    }
   ],
   "source": [
    "# Find similar goal groups using batch processing (memory efficient)\n",
    "# Uses Union-Find to properly merge groups across batches\n",
    "SIMILARITY_THRESHOLD = 0.9  # Adjustable threshold\n",
    "BATCH_SIZE = 1000  # Process 1000 goals at a time\n",
    "\n",
    "# Check if similarity results already exist\n",
    "import pickle as pkl\n",
    "similarity_cache_file = '../Data/Embeddings, Similarity and Language Detection/similarity_results_cache.pkl'\n",
    "\n",
    "if os.path.exists(similarity_cache_file):\n",
    "    print(f\"\\nLoading existing similarity results from {similarity_cache_file}...\")\n",
    "    \n",
    "    # Load cached results\n",
    "    with open(similarity_cache_file, 'rb') as f:\n",
    "        cache_data = pkl.load(f)\n",
    "    \n",
    "    # Verify threshold matches\n",
    "    if cache_data['threshold'] == SIMILARITY_THRESHOLD:\n",
    "        print(f\"Loaded similarity results (threshold = {SIMILARITY_THRESHOLD})\")\n",
    "        \n",
    "        # Extract cached variables\n",
    "        similar_groups = cache_data['similar_groups']\n",
    "        groups_dict = cache_data['groups_dict']\n",
    "        parent = cache_data['parent']\n",
    "        total_in_groups = cache_data['total_in_groups']\n",
    "        num_merged = cache_data['num_merged']\n",
    "        total_goals_with_desc_in_groups = cache_data['total_goals_with_desc_in_groups']\n",
    "        \n",
    "        # Reconstruct find and union functions (needed by subsequent cells)\n",
    "        def find(x):\n",
    "            \"\"\"Find root of element x with path compression\"\"\"\n",
    "            if parent[x] != x:\n",
    "                parent[x] = find(parent[x])\n",
    "            return parent[x]\n",
    "        \n",
    "        def union(x, y):\n",
    "            \"\"\"Union two elements\"\"\"\n",
    "            root_x = find(x)\n",
    "            root_y = find(y)\n",
    "            if root_x != root_y:\n",
    "                parent[root_y] = root_x\n",
    "        \n",
    "        print(f\"\\nLoaded {len(similar_groups):,} groups of similar goals\")\n",
    "        print(f\"\\nGroup statistics:\")\n",
    "        print(f\"  Total goals in groups: {total_in_groups:,}\")\n",
    "        print(f\"  Goals with descriptions in groups: {total_goals_with_desc_in_groups:,}\")\n",
    "        print(f\"  Groups (representatives): {len(similar_groups):,}\")\n",
    "        print(f\"  Goals merged: {num_merged:,}\")\n",
    "        print(f\"  Reduction: {num_merged:,} goals ({100*num_merged/len(goals):.1f}% of all goals)\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Warning: Cached threshold ({cache_data['threshold']}) doesn't match current threshold ({SIMILARITY_THRESHOLD})\")\n",
    "        print(\"Recomputing similarities with current threshold...\")\n",
    "        similarity_cache_file = None  # Force recomputation\n",
    "\n",
    "if not os.path.exists(similarity_cache_file) or cache_data['threshold'] != SIMILARITY_THRESHOLD:\n",
    "    # Compute similarities from scratch\n",
    "    print(f\"\\nFinding similar groups (threshold = {SIMILARITY_THRESHOLD})...\")\n",
    "    print(f\"Processing in batches of {BATCH_SIZE} with proper cross-batch merging...\\n\")\n",
    "    \n",
    "    # Union-Find data structure to properly merge groups\n",
    "    parent = {gid: gid for gid in goal_ids_for_embedding}\n",
    "    \n",
    "    def find(x):\n",
    "        \"\"\"Find root of element x with path compression\"\"\"\n",
    "        if parent[x] != x:\n",
    "            parent[x] = find(parent[x])\n",
    "        return parent[x]\n",
    "    \n",
    "    def union(x, y):\n",
    "        \"\"\"Union two elements\"\"\"\n",
    "        root_x = find(x)\n",
    "        root_y = find(y)\n",
    "        if root_x != root_y:\n",
    "            parent[root_y] = root_x\n",
    "    \n",
    "    num_batches = (len(embeddings) + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "    \n",
    "    # Process batches and build union-find structure\n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * BATCH_SIZE\n",
    "        end_idx = min((batch_idx + 1) * BATCH_SIZE, len(embeddings))\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"  Processing batch {batch_idx + 1}/{num_batches} (goals {start_idx:,} to {end_idx:,})...\")\n",
    "        \n",
    "        # Compute similarities for this batch against ALL embeddings\n",
    "        batch_embeddings = embeddings[start_idx:end_idx]\n",
    "        batch_similarities = cosine_similarity(batch_embeddings, embeddings)\n",
    "        \n",
    "        # For each goal in batch, find all similar goals and union them\n",
    "        for i in range(len(batch_embeddings)):\n",
    "            global_i = start_idx + i\n",
    "            gid_i = goal_ids_for_embedding[global_i]\n",
    "            \n",
    "            # Find all goals similar to this one (across all batches)\n",
    "            similar_indices = np.where(batch_similarities[i] >= SIMILARITY_THRESHOLD)[0]\n",
    "            \n",
    "            # Union all similar goals together\n",
    "            for j in similar_indices:\n",
    "                gid_j = goal_ids_for_embedding[j]\n",
    "                union(gid_i, gid_j)\n",
    "    \n",
    "    print(\"\\nSimilarity computation complete. Building final groups...\\n\")\n",
    "    \n",
    "    # Group goals by their root (representative in union-find)\n",
    "    groups_dict = defaultdict(list)\n",
    "    \n",
    "    for gid in goal_ids_for_embedding:\n",
    "        root = find(gid)\n",
    "        groups_dict[root].append(gid)\n",
    "    \n",
    "    # Filter to groups with size > 1 and at least one description\n",
    "    similar_groups = []\n",
    "    \n",
    "    for root, members in groups_dict.items():\n",
    "        if len(members) > 1:\n",
    "            # Check if at least one member has a valid description\n",
    "            members_with_desc = [gid for gid in members if gid in goals_with_descriptions]\n",
    "            \n",
    "            if len(members_with_desc) > 0:\n",
    "                # Sort by popularity - only among those with descriptions\n",
    "                members_with_desc_sorted = sorted(members_with_desc, \n",
    "                                                  key=lambda x: included_by_our_users.get(x, 0), \n",
    "                                                  reverse=True)\n",
    "                \n",
    "                # Most popular goal WITH description becomes representative\n",
    "                representative = members_with_desc_sorted[0]\n",
    "                \n",
    "                # Sort all members by popularity\n",
    "                members_sorted = sorted(members, key=lambda x: included_by_our_users.get(x, 0), reverse=True)\n",
    "                \n",
    "                similar_groups.append({\n",
    "                    'representative': representative,\n",
    "                    'members': members_sorted,\n",
    "                    'members_with_desc': members_with_desc_sorted,\n",
    "                    'included_by_our_users': [included_by_our_users.get(gid, 0) for gid in members_sorted]\n",
    "                })\n",
    "    \n",
    "    print(f\"Found {len(similar_groups):,} groups of similar goals (with at least one description)\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_in_groups = sum(len(g['members']) for g in similar_groups)\n",
    "    num_merged = total_in_groups - len(similar_groups)\n",
    "    total_goals_with_desc_in_groups = sum(len(g['members_with_desc']) for g in similar_groups)\n",
    "    \n",
    "    print(f\"\\nGroup statistics:\")\n",
    "    print(f\"  Total goals in groups: {total_in_groups:,}\")\n",
    "    print(f\"  Goals with descriptions in groups: {total_goals_with_desc_in_groups:,}\")\n",
    "    print(f\"  Groups (representatives): {len(similar_groups):,}\")\n",
    "    print(f\"  Goals merged: {num_merged:,}\")\n",
    "    print(f\"  Reduction: {num_merged:,} goals ({100*num_merged/len(goals):.1f}% of all goals)\")\n",
    "    \n",
    "    # Save results to cache file\n",
    "    print(f\"\\nSaving similarity results to {similarity_cache_file}...\")\n",
    "    cache_data = {\n",
    "        'threshold': SIMILARITY_THRESHOLD,\n",
    "        'similar_groups': similar_groups,\n",
    "        'groups_dict': dict(groups_dict),  # Convert defaultdict to dict for pickling\n",
    "        'parent': parent,\n",
    "        'total_in_groups': total_in_groups,\n",
    "        'num_merged': num_merged,\n",
    "        'total_goals_with_desc_in_groups': total_goals_with_desc_in_groups\n",
    "    }\n",
    "    \n",
    "    with open(similarity_cache_file, 'wb') as f:\n",
    "        pkl.dump(cache_data, f)\n",
    "    \n",
    "    print(\"Similarity results cached successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715dd70e",
   "metadata": {},
   "source": [
    "## 7. Analyze Similar Goal Groups\n",
    "Show statistics for all groups found, not just those with descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a4b31d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comprehensive group analysis:\n",
      "\n",
      "TOTAL GROUPS FOUND (similarity >= 0.9):\n",
      "  Total groups: 17,098\n",
      "  Groups WITH at least 1 description: 283 (1.7%)\n",
      "  Groups WITHOUT any description: 16,815 (98.3%)\n",
      "\n",
      "GOALS IN GROUPS:\n",
      "  Total goals in all groups: 82,350\n",
      "  Goals in groups WITH description: 866\n",
      "  Goals in groups WITHOUT description: 81,484\n",
      "\n",
      "EXCLUDED FROM ANALYSIS:\n",
      "  Groups excluded (no descriptions): 16,815\n",
      "  Goals excluded (in groups without descriptions): 81,484\n",
      "  Note: These groups were found but excluded from Excel/network because no member has a description\n",
      "\n",
      "GROUP SIZE STATISTICS:\n",
      "\n",
      "  Groups WITH description:\n",
      "    - Mean size: 3.1\n",
      "    - Median size: 2\n",
      "    - Max size: 43\n",
      "    - Min size: 2\n",
      "\n",
      "  Groups WITHOUT description:\n",
      "    - Mean size: 4.8\n",
      "    - Median size: 2\n",
      "    - Max size: 738\n",
      "    - Min size: 2\n"
     ]
    }
   ],
   "source": [
    "# Analyze ALL groups found by Union-Find (including those without descriptions)\n",
    "print(\"\\nComprehensive group analysis:\")\n",
    "\n",
    "# Count all groups (size > 1)\n",
    "all_groups_info = []\n",
    "\n",
    "for root, members in groups_dict.items():\n",
    "    if len(members) > 1:\n",
    "        members_with_desc = [gid for gid in members if gid in goals_with_descriptions]\n",
    "        has_any_description = len(members_with_desc) > 0\n",
    "        \n",
    "        all_groups_info.append({\n",
    "            'members': members,\n",
    "            'members_with_desc': members_with_desc,\n",
    "            'has_description': has_any_description,\n",
    "            'size': len(members)\n",
    "        })\n",
    "\n",
    "# Split into two categories\n",
    "groups_with_desc = [g for g in all_groups_info if g['has_description']]\n",
    "groups_without_desc = [g for g in all_groups_info if not g['has_description']]\n",
    "\n",
    "print(f\"\\nTOTAL GROUPS FOUND (similarity >= {SIMILARITY_THRESHOLD}):\")\n",
    "print(f\"  Total groups: {len(all_groups_info):,}\")\n",
    "print(f\"  Groups WITH at least 1 description: {len(groups_with_desc):,} ({100*len(groups_with_desc)/len(all_groups_info):.1f}%)\")\n",
    "print(f\"  Groups WITHOUT any description: {len(groups_without_desc):,} ({100*len(groups_without_desc)/len(all_groups_info):.1f}%)\")\n",
    "\n",
    "total_goals_in_all_groups = sum(g['size'] for g in all_groups_info)\n",
    "total_goals_in_groups_with_desc = sum(g['size'] for g in groups_with_desc)\n",
    "total_goals_in_groups_without_desc = sum(g['size'] for g in groups_without_desc)\n",
    "\n",
    "print(f\"\\nGOALS IN GROUPS:\")\n",
    "print(f\"  Total goals in all groups: {total_goals_in_all_groups:,}\")\n",
    "print(f\"  Goals in groups WITH description: {total_goals_in_groups_with_desc:,}\")\n",
    "print(f\"  Goals in groups WITHOUT description: {total_goals_in_groups_without_desc:,}\")\n",
    "\n",
    "print(f\"\\nEXCLUDED FROM ANALYSIS:\")\n",
    "print(f\"  Groups excluded (no descriptions): {len(groups_without_desc):,}\")\n",
    "print(f\"  Goals excluded (in groups without descriptions): {total_goals_in_groups_without_desc:,}\")\n",
    "print(f\"  Note: These groups were found but excluded from Excel/network because no member has a description\")\n",
    "\n",
    "# Group size statistics\n",
    "with_desc_sizes = [g['size'] for g in groups_with_desc]\n",
    "without_desc_sizes = [g['size'] for g in groups_without_desc]\n",
    "\n",
    "print(f\"\\nGROUP SIZE STATISTICS:\")\n",
    "print(f\"\\n  Groups WITH description:\")\n",
    "print(f\"    - Mean size: {np.mean(with_desc_sizes):.1f}\")\n",
    "print(f\"    - Median size: {np.median(with_desc_sizes):.0f}\")\n",
    "print(f\"    - Max size: {max(with_desc_sizes):,}\")\n",
    "print(f\"    - Min size: {min(with_desc_sizes):,}\")\n",
    "\n",
    "print(f\"\\n  Groups WITHOUT description:\")\n",
    "print(f\"    - Mean size: {np.mean(without_desc_sizes):.1f}\")\n",
    "print(f\"    - Median size: {np.median(without_desc_sizes):.0f}\")\n",
    "print(f\"    - Max size: {max(without_desc_sizes):,}\")\n",
    "print(f\"    - Min size: {min(without_desc_sizes):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797c4ed5",
   "metadata": {},
   "source": [
    "Show concrete examples from both types of groups (with and without descriptions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a559d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example groups with descriptions (included in analysis):\n",
      "\n",
      "Example 1: 43 similar goals (1 with descriptions)\n",
      "  [desc] [1] Leave an inspirational note inside a book for someone to fin (pop: 1183)\n",
      "  [none] [2] Leave an inspirational note inside of a book for someone to  (pop:    2)\n",
      "  [none] [3] Leave an inspirational note inside a book for someone        (pop:   56)\n",
      "  [none] [4] Leave an inspirational note in a book                        (pop:    3)\n",
      "  [none] [5] Leave an inspirational note inside a library book            (pop:    2)\n",
      "  ... and 38 more similar goals\n",
      "\n",
      "Example 2: 3 similar goals (3 with descriptions)\n",
      "  [desc] [1] Learn French                                                 (pop:  161)\n",
      "  [desc] [2] Improve my French                                            (pop:   64)\n",
      "  [desc] [3] Learn to speak French                                        (pop:   20)\n",
      "\n",
      "\n",
      "\n",
      "Example groups without descriptions (excluded from analysis):\n",
      "Note: These groups were found but excluded because NO member has a description\n",
      "\n",
      "Example 1: 7 similar goals (0 with descriptions)\n",
      "    [1] Try Geocaching                                               (pop:  104)\n",
      "        Description: ''\n",
      "    [2] Try Geocaching/Find One                                      (pop:    1)\n",
      "        Description: ''\n",
      "    [3] Look into geocaching                                         (pop:    1)\n",
      "        Description: ''\n",
      "    [4] Try geocaching                                               (pop:    8)\n",
      "        Description: ''\n",
      "    [5] try geocaching                                               (pop:    2)\n",
      "        Description: ''\n",
      "  ... and 2 more similar goals\n",
      "\n",
      "Example 2: 30 similar goals (0 with descriptions)\n",
      "    [1] Send a secret to PostSecret                                  (pop:  627)\n",
      "        Description: ''\n",
      "    [2] Send in a secret to PostSecret                               (pop:    4)\n",
      "        Description: ''\n",
      "    [3] Submit a secret to postsecret                                (pop:    1)\n",
      "        Description: ''\n",
      "    [4] Mail a secret to postsecret                                  (pop:    8)\n",
      "        Description: ''\n",
      "    [5] Send a secret to postsecret.com                              (pop:    3)\n",
      "        Description: ''\n",
      "  ... and 25 more similar goals\n",
      "\n",
      "\n",
      "\n",
      "Only the 283 groups WITH descriptions are used in the Excel file and network\n"
     ]
    }
   ],
   "source": [
    "# Show examples of BOTH types of groups\n",
    "print(\"\\nExample groups with descriptions (included in analysis):\")\n",
    "\n",
    "for i, group_info in enumerate(groups_with_desc[:2], 1):\n",
    "    members = group_info['members']\n",
    "    members_with_desc = group_info['members_with_desc']   \n",
    "    print(f\"\\nExample {i}: {len(members)} similar goals ({len(members_with_desc)} with descriptions)\")\n",
    "    \n",
    "    for j, gid in enumerate(members[:5], 1):  # Show first 5\n",
    "        title = goals[gid]['title']\n",
    "        has_desc = \"[desc]\" if gid in goals_with_descriptions else \"[none]\"\n",
    "        pop = included_by_our_users.get(gid, 0)\n",
    "        print(f\"  {has_desc} [{j}] {title[:60]:<60} (pop: {pop:>4})\")\n",
    "    \n",
    "    if len(members) > 5:\n",
    "        print(f\"  ... and {len(members) - 5} more similar goals\")\n",
    "\n",
    "print(\"\\n\\n\\nExample groups without descriptions (excluded from analysis):\")\n",
    "print(\"Note: These groups were found but excluded because NO member has a description\")\n",
    "\n",
    "for i, group_info in enumerate(groups_without_desc[:2], 1):\n",
    "    members = group_info['members']\n",
    "    print(f\"\\nExample {i}: {len(members)} similar goals (0 with descriptions)\")\n",
    "    \n",
    "    for j, gid in enumerate(members[:5], 1):  # Show first 5\n",
    "        title = goals[gid]['title']\n",
    "        pop = included_by_our_users.get(gid, 0)\n",
    "        desc = goals[gid].get('description', '')\n",
    "        print(f\"    [{j}] {title[:60]:<60} (pop: {pop:>4})\")\n",
    "        print(f\"        Description: '{desc[:80]}'\")\n",
    "    \n",
    "    if len(members) > 5:\n",
    "        print(f\"  ... and {len(members) - 5} more similar goals\")\n",
    "\n",
    "print(f\"\\n\\n\\nOnly the {len(groups_with_desc):,} groups WITH descriptions are used in the Excel file and network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f205de11",
   "metadata": {},
   "source": [
    "## 8. Create Goal Mapping and Export to Excel\n",
    "Create mapping from all goals to their representatives and export for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2daa4cc",
   "metadata": {},
   "source": [
    "Visualize the representative selection process with detailed examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb6c169d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example similar goal groups:\n",
      "Showing first 5 groups with selection process:\n",
      "\n",
      "Group 1: 43 similar goals (1 with descriptions)\n",
      "  [desc] [1] Leave an inspirational note inside a book for (pop: 1183, 9856W/966D) <<< SELECTED\n",
      "  [none] [2] Leave an inspirational note for someone to fi (pop:   59, 390W/54D) \n",
      "  [none] [3] Leave an inspirational note inside a book for (pop:   56, 260W/33D) \n",
      "  [none] [4] Leave an inspirational note in a book for som (pop:   44, 295W/37D) \n",
      "  [none] [5] Leave an inspirational note inside a book for (pop:   24, 74W/10D) \n",
      "  [none] [6] leave an inspirational note inside a book for (pop:    6, 39W/4D) \n",
      "  [none] [7] Leave an inspirational note inside a library  (pop:    5, 41W/3D) \n",
      "  [none] [8] leave an inspirational note in a book for som (pop:    4, 11W/3D) \n",
      "  [none] [9] Leave an inspirational note in a book         (pop:    3, 14W/3D) \n",
      "  [none] [10] Leave an inspirational note in a library book (pop:    3, 6W/0D) \n",
      "  [none] [11] Leave an inspirational note inside of a book  (pop:    2, 4W/0D) \n",
      "  [none] [12] Leave an inspirational note inside a library  (pop:    2, 9W/0D) \n",
      "  [none] [13] Leave an Inspirational Note Inside a Book for (pop:    2, 6W/0D) \n",
      "  [none] [14] Leave an inspiring note in a book for a rando (pop:    2, 2W/0D) \n",
      "  [none] [15] Leave an inspirational note in a library book (pop:    2, 2W/0D) \n",
      "  [none] [16] Write an inspirational note and leave it in a (pop:    1, 1W/0D) \n",
      "  [none] [17] Leave inspirational notes in a library        (pop:    1, 1W/0D) \n",
      "  [none] [18] leave a book I love with an inspirational not (pop:    1, 1W/0D) \n",
      "  [none] [19] Leave an inspirational note somewhere for som (pop:    1, 2W/0D) \n",
      "  [none] [20] Leave An Inspirational Note In A Book         (pop:    1, 1W/0D) \n",
      "  [none] [21] leave an inspirational note for someone to fi (pop:    1, 5W/0D) \n",
      "  [none] [22] Leave an inspirational note somewhere for a s (pop:    1, 1W/0D) \n",
      "  [none] [23] leave and inspirational note in a book for so (pop:    1, 1W/0D) \n",
      "  [none] [24] Leave an inspirational note behind for someon (pop:    1, 1W/0D) \n",
      "  [none] [25] Leave inspirational notes (25) for someone to (pop:    1, 1W/0D) \n",
      "  [none] [26] Leave an inspirational note in a library book (pop:    1, 3W/0D) \n",
      "  [none] [27] Leave an inspirational note inside every libr (pop:    1, 1W/0D) \n",
      "  [none] [28] leave an inspiring note in a book for a stran (pop:    1, 1W/0D) \n",
      "  [none] [29] leave an inspirational note inside a book     (pop:    1, 2W/0D) \n",
      "  [none] [30] leave an inspirational note inside of a book  (pop:    1, 1W/0D) \n",
      "  [none] [31] leave an inspirational note in a library book (pop:    1, 1W/0D) \n",
      "  [none] [32] Write an inspirational note in a library book (pop:    1, 1W/0D) \n",
      "  [none] [33] Leave an inspirational note in a book for som (pop:    1, 1W/0D) \n",
      "  [none] [34] Write an inspirational note inside a book for (pop:    1, 1W/0D) \n",
      "  [none] [35] leave a inspirational note in a book for some (pop:    1, 1W/0D) \n",
      "  [none] [36] write an inspirational note and put it in a r (pop:    1, 1W/0D) \n",
      "  [none] [37] Leave an inspirational library book note      (pop:    1, 1W/0D) \n",
      "  [none] [38] leave an inspirational note inside a book for (pop:    1, 1W/0D) \n",
      "  [none] [39] Leave an inspirational note inside a book for (pop:    1, 3W/0D) \n",
      "  [none] [40] Leave an inspirational note inside a book in  (pop:    1, 1W/0D) \n",
      "  [none] [41] write an inspirational note and leave it in a (pop:    1, 2W/0D) \n",
      "  [none] [42] Leave an inspirational note inside a book     (pop:    1, 7W/0D) \n",
      "  [none] [43] Leave an inspirational note inside a book for (pop:    1, 7W/0D) \n",
      "\n",
      "  Selected: Leave an inspirational note inside a book for someone to find\n",
      "  Reason: Most popular goal WITH description (1183 occurrences)\n",
      "\n",
      "Group 2: 3 similar goals (3 with descriptions)\n",
      "  [desc] [1] Learn French                                  (pop:  161, 1466W/153D) <<< SELECTED\n",
      "  [desc] [2] Improve my French                             (pop:   64, 412W/47D) \n",
      "  [desc] [3] Learn to speak French                         (pop:   20, 168W/46D) \n",
      "\n",
      "  Selected: Learn French\n",
      "  Reason: Most popular goal WITH description (161 occurrences)\n",
      "\n",
      "Group 3: 8 similar goals (8 with descriptions)\n",
      "  [desc] [1] See the Northern Lights                       (pop:  926, 9451W/747D) <<< SELECTED\n",
      "  [desc] [2] Gaze at the Aurora Borealis                   (pop:   47, 573W/36D) \n",
      "  [desc] [3] See the Aurora Borealis                       (pop:   42, 367W/36D) \n",
      "  [desc] [4] See the Northern Lights in Scandinavia        (pop:   26, 391W/16D) \n",
      "  [desc] [5] Witness the Northern Lights                   (pop:    9, 169W/20D) \n",
      "  [desc] [6] Photograph the Northern Lights                (pop:    8, 124W/14D) \n",
      "  [desc] [7] See the Aurora Australis                      (pop:    2, 8W/0D) \n",
      "  [desc] [8] Witness the Aurora Australis in Tasmania      (pop:    1, 10W/0D) \n",
      "\n",
      "  Selected: See the Northern Lights\n",
      "  Reason: Most popular goal WITH description (926 occurrences)\n",
      "\n",
      "Group 4: 7 similar goals (7 with descriptions)\n",
      "  [desc] [1] Visit Paris                                   (pop:  128, 1253W/718D) <<< SELECTED\n",
      "  [desc] [2] Go to Paris                                   (pop:   88, 697W/235D) \n",
      "  [desc] [3] Travel to Paris                               (pop:   42, 243W/156D) \n",
      "  [desc] [4] Go to Paris, France                           (pop:   16, 117W/72D) \n",
      "  [desc] [5] Travel to Paris, France                       (pop:   14, 78W/64D) \n",
      "  [desc] [6] Live in Paris                                 (pop:    8, 81W/16D) \n",
      "  [desc] [7] Spend a weekend in Paris                      (pop:    1, 8W/0D) \n",
      "\n",
      "  Selected: Visit Paris\n",
      "  Reason: Most popular goal WITH description (128 occurrences)\n",
      "\n",
      "Group 5: 2 similar goals (2 with descriptions)\n",
      "  [desc] [1] Read 3 books from the banned books list       (pop:   82, 574W/84D) <<< SELECTED\n",
      "  [desc] [2] Read 3 books from the banned books list       (pop:   28, 213W/52D) \n",
      "\n",
      "  Selected: Read 3 books from the banned books list\n",
      "  Reason: Most popular goal WITH description (82 occurrences)\n"
     ]
    }
   ],
   "source": [
    "# Show example groups\n",
    "print(\"\\nExample similar goal groups:\")\n",
    "print(f\"Showing first 5 groups with selection process:\")\n",
    "\n",
    "for i, group in enumerate(similar_groups[:5], 1):\n",
    "    rep = group['representative']\n",
    "    members = group['members']\n",
    "    members_with_desc = group['members_with_desc']\n",
    "    pops = group['included_by_our_users']\n",
    "    \n",
    "    print(f\"\\nGroup {i}: {len(members)} similar goals ({len(members_with_desc)} with descriptions)\")\n",
    "    \n",
    "    for j, (gid, pop) in enumerate(zip(members, pops)):\n",
    "        title = goals[gid]['title']\n",
    "        has_desc = \"[desc]\" if gid in goals_with_descriptions else \"[none]\"\n",
    "        is_rep = \"<<< SELECTED\" if gid == rep else \"\"\n",
    "        wants = goals[gid]['wants_to_do']\n",
    "        have = goals[gid]['have_done']\n",
    "        print(f\"  {has_desc} [{j+1}] {title[:45]:<45} (pop: {pop:>4}, {wants}W/{have}D) {is_rep}\")\n",
    "    \n",
    "    print(f\"\\n  Selected: {goals[rep]['title']}\")\n",
    "    print(f\"  Reason: Most popular goal WITH description ({included_by_our_users.get(rep, 0)} occurrences)\")\n",
    "    \n",
    "    if i == 10:\n",
    "        print(f\"\\n... (showing first 10 of {len(similar_groups)} total groups)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dc692d",
   "metadata": {},
   "source": [
    "Build the complete mapping dictionary and prepare data for Excel export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29032a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created mapping for 866 goals\n",
      "\n",
      "Mapping DataFrame created: 866 rows\n",
      "Columns: ['group_id', 'is_representative', 'goal_id', 'goal_title', 'goal_description', 'has_description', 'included_by_our_users', 'wants_to_do', 'have_done', 'num_comments', 'num_tags', 'representative_id', 'representative_title', 'representative_description', 'representative_included_by_our_users', 'group_size', 'position_in_group']\n",
      "\n",
      "Sample mapping data:\n",
      " group_id  is_representative  goal_id                                                            goal_title                                                                                                                                                                                         goal_description  has_description  included_by_our_users  wants_to_do  have_done  num_comments  num_tags representative_id                                          representative_title                                                                                                                                                                               representative_description  representative_included_by_our_users  group_size  position_in_group\n",
      "        1               True nnEnjr7O         Leave an inspirational note inside a book for someone to find Imagine the joy of discovering a heartfelt message nestled within the pages of a book, a simple yet profound gesture that can brighten someone's day or even change their perspective. The goal of leavi             True                   1183         9856        966            56        46          nnEnjr7O Leave an inspirational note inside a book for someone to find Imagine the joy of discovering a heartfelt message nestled within the pages of a book, a simple yet profound gesture that can brighten someone's day or even change their perspective. The goal of leavi                                  1183          43                  1\n",
      "        1              False C7HjQDOv                       Leave an inspirational note for someone to find                                                                                                                                                                                                                     False                     59          390         54             6        30          nnEnjr7O Leave an inspirational note inside a book for someone to find Imagine the joy of discovering a heartfelt message nestled within the pages of a book, a simple yet profound gesture that can brighten someone's day or even change their perspective. The goal of leavi                                  1183          43                  2\n",
      "        1              False uusxErhp                 Leave an inspirational note inside a book for someone                                                                                                                                                                                                                     False                     56          260         33             8        22          nnEnjr7O Leave an inspirational note inside a book for someone to find Imagine the joy of discovering a heartfelt message nestled within the pages of a book, a simple yet profound gesture that can brighten someone's day or even change their perspective. The goal of leavi                                  1183          43                  3\n",
      "        1              False qEanrQva             Leave an inspirational note in a book for someone to find                                                                                                                                                                                                                     False                     44          295         37             5        33          nnEnjr7O Leave an inspirational note inside a book for someone to find Imagine the joy of discovering a heartfelt message nestled within the pages of a book, a simple yet profound gesture that can brighten someone's day or even change their perspective. The goal of leavi                                  1183          43                  4\n",
      "        1              False Qkrpqnrb         Leave an inspirational note inside a book for someone to find                                                                                                                                                                                                                     False                     24           74         10             2         0          nnEnjr7O Leave an inspirational note inside a book for someone to find Imagine the joy of discovering a heartfelt message nestled within the pages of a book, a simple yet profound gesture that can brighten someone's day or even change their perspective. The goal of leavi                                  1183          43                  5\n",
      "        1              False Edgh6NNY         leave an inspirational note inside a book for someone to find                                                                                                                                                                                                                     False                      6           39          4             0         0          nnEnjr7O Leave an inspirational note inside a book for someone to find Imagine the joy of discovering a heartfelt message nestled within the pages of a book, a simple yet profound gesture that can brighten someone's day or even change their perspective. The goal of leavi                                  1183          43                  6\n",
      "        1              False jC1rdH7t Leave an inspirational note inside a library book for someone to find                                                                                                                                                                                                                     False                      5           41          3             0         0          nnEnjr7O Leave an inspirational note inside a book for someone to find Imagine the joy of discovering a heartfelt message nestled within the pages of a book, a simple yet profound gesture that can brighten someone's day or even change their perspective. The goal of leavi                                  1183          43                  7\n",
      "        1              False 2AGeaN2t             leave an inspirational note in a book for someone to find                                                                                                                                                                                                                     False                      4           11          3             1         0          nnEnjr7O Leave an inspirational note inside a book for someone to find Imagine the joy of discovering a heartfelt message nestled within the pages of a book, a simple yet profound gesture that can brighten someone's day or even change their perspective. The goal of leavi                                  1183          43                  8\n",
      "        1              False cLxGQdPl                                 Leave an inspirational note in a book                                                                                                                                                                                                                     False                      3           14          3             2         0          nnEnjr7O Leave an inspirational note inside a book for someone to find Imagine the joy of discovering a heartfelt message nestled within the pages of a book, a simple yet profound gesture that can brighten someone's day or even change their perspective. The goal of leavi                                  1183          43                  9\n",
      "        1              False uGj5rqoH                         Leave an inspirational note in a library book                                                                                                                                                                                                                     False                      3            6          0             0         0          nnEnjr7O Leave an inspirational note inside a book for someone to find Imagine the joy of discovering a heartfelt message nestled within the pages of a book, a simple yet profound gesture that can brighten someone's day or even change their perspective. The goal of leavi                                  1183          43                 10\n"
     ]
    }
   ],
   "source": [
    "# Create mapping dictionary\n",
    "goal_mapping = {}\n",
    "\n",
    "# Map each goal in a group to its representative\n",
    "for group in similar_groups:\n",
    "    rep = group['representative']\n",
    "    for member in group['members']:\n",
    "        goal_mapping[member] = rep\n",
    "\n",
    "print(f\"Created mapping for {len(goal_mapping):,} goals\")\n",
    "\n",
    "# Create detailed mapping for export\n",
    "mapping_data = []\n",
    "\n",
    "for group in similar_groups:\n",
    "    rep = group['representative']\n",
    "    rep_data = goals[rep]  # Use main goals dict (rep always has description)\n",
    "    rep_pop = included_by_our_users.get(rep, 0)\n",
    "    \n",
    "    for i, (member, pop) in enumerate(zip(group['members'], group['included_by_our_users'])):\n",
    "        member_data = goals[member]  # Use main goals dict (some members may not have descriptions)\n",
    "        \n",
    "        # Get description (may be empty for some members)\n",
    "        member_desc = member_data.get('description', '')\n",
    "        rep_desc = rep_data.get('description', '')\n",
    "        \n",
    "        mapping_data.append({\n",
    "            'group_id': similar_groups.index(group) + 1,\n",
    "            'is_representative': member == rep,\n",
    "            'goal_id': member,\n",
    "            'goal_title': member_data['title'],\n",
    "            'goal_description': member_desc[:200] if member_desc else '',  # Truncate for Excel\n",
    "            'has_description': member in goals_with_descriptions,\n",
    "            'included_by_our_users': pop,\n",
    "            'wants_to_do': member_data['wants_to_do'],\n",
    "            'have_done': member_data['have_done'],\n",
    "            'num_comments': len(member_data['comments']),\n",
    "            'num_tags': len(member_data['tags']),\n",
    "            'representative_id': rep,\n",
    "            'representative_title': rep_data['title'],\n",
    "            'representative_description': rep_desc[:200] if rep_desc else '',\n",
    "            'representative_included_by_our_users': rep_pop,\n",
    "            'group_size': len(group['members']),\n",
    "            'position_in_group': i + 1\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "mapping_df = pd.DataFrame(mapping_data)\n",
    "\n",
    "# Sort by group_id and position\n",
    "mapping_df = mapping_df.sort_values(['group_id', 'position_in_group'])\n",
    "\n",
    "print(f\"\\nMapping DataFrame created: {len(mapping_df):,} rows\")\n",
    "print(f\"Columns: {list(mapping_df.columns)}\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample mapping data:\")\n",
    "print(mapping_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38ace6d",
   "metadata": {},
   "source": [
    "Export the mapping to Excel with three sheets: Goal Mapping, Summary, and Representatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f72ecaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to ../Data/Validation/goal_mapping_validation.xlsx\n",
      "  - Sheet 'Goal Mapping': 866 rows (all goals in groups)\n",
      "  - Sheet 'Summary': Overview statistics\n",
      "  - Sheet 'Representatives': 283 representative goals\n"
     ]
    }
   ],
   "source": [
    "# Export to Excel\n",
    "output_file = '../Data/Validation/goal_mapping_validation.xlsx'\n",
    "\n",
    "# Calculate num_unique_after_merge for summary\n",
    "num_unique_after_merge = len(goals_with_descriptions) - num_merged\n",
    "\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    # Main mapping sheet\n",
    "    mapping_df.to_excel(writer, sheet_name='Goal Mapping', index=False)\n",
    "    \n",
    "    # Summary sheet\n",
    "    summary_data = {\n",
    "        'Metric': [\n",
    "            'Total goals with descriptions',\n",
    "            'Similar groups found',\n",
    "            'Goals merged',\n",
    "            'Unique goals after merge',\n",
    "            'Reduction percentage',\n",
    "            'Similarity threshold used'\n",
    "        ],\n",
    "        'Value': [\n",
    "            len(goals_with_descriptions),\n",
    "            len(similar_groups),\n",
    "            num_merged,\n",
    "            num_unique_after_merge,\n",
    "            f\"{100*num_merged/len(goals_with_descriptions):.2f}%\",\n",
    "            SIMILARITY_THRESHOLD\n",
    "        ]\n",
    "    }\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
    "    \n",
    "    # Representatives only (for final network)\n",
    "    representatives_data = []\n",
    "    for group in similar_groups:\n",
    "        rep = group['representative']\n",
    "        rep_data = goals_with_descriptions[rep]\n",
    "        representatives_data.append({\n",
    "            'goal_id': rep,\n",
    "            'title': rep_data['title'],\n",
    "            'description': rep_data['description'],\n",
    "            'wants_to_do': rep_data['wants_to_do'],\n",
    "            'have_done': rep_data['have_done'],\n",
    "            'num_comments': len(rep_data['comments']),\n",
    "            'num_tags': len(rep_data['tags']),\n",
    "            'included_by_our_users': included_by_our_users.get(rep, 0),\n",
    "            'group_size': len(group['members']),\n",
    "            'merged_goal_ids': ', '.join(group['members'][1:])  # All except representative\n",
    "        })\n",
    "    \n",
    "    rep_df = pd.DataFrame(representatives_data)\n",
    "    rep_df = rep_df.sort_values('included_by_our_users', ascending=False)\n",
    "    rep_df.to_excel(writer, sheet_name='Representatives', index=False)\n",
    "\n",
    "print(f\"Exported to {output_file}\")\n",
    "print(f\"  - Sheet 'Goal Mapping': {len(mapping_df)} rows (all goals in groups)\")\n",
    "print(f\"  - Sheet 'Summary': Overview statistics\")\n",
    "print(f\"  - Sheet 'Representatives': {len(representatives_data)} representative goals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bd10b6",
   "metadata": {},
   "source": [
    "## 9. Create Filtered Network with Merged Goals\n",
    "Rebuild network using only goals with descriptions and merge similar goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8423e087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building filtered network...\n",
      "(Only goals with descriptions, merging similar goals)\n",
      "\n",
      "Added merged_goals attribute to all nodes\n",
      "  Representatives (with merged goals): 283\n",
      "  Non-representatives (empty list): 2,607\n",
      "\n",
      "Filtered & merged network statistics:\n",
      "  Nodes: 2,890\n",
      "  Edges: 219,130\n",
      "  Density: 0.05249119\n",
      "  Average degree: 151.65\n",
      "\n",
      "  Connected components: 28\n",
      "  Largest component: 2,860 nodes (99.0%)\n",
      "\n",
      "================================================================================\n",
      "COMPARISON: ORIGINAL vs FILTERED & MERGED\n",
      "\n",
      "Comparison: Original vs Filtered & Merged\n",
      "Metric                    Original             Filtered & Merged    Change              \n",
      "Nodes                     3,394                2,890                -504 (-14.8%)\n",
      "Edges                     258,027              219,130              -38,897 (-15.1%)\n",
      "Density                   0.04481253           0.05249119           +0.00767867 (+17.1%)\n",
      "\n",
      "================================================================================\n",
      "SAMPLE NODE ATTRIBUTES IN FILTERED NETWORK\n",
      "================================================================================\n",
      "\n",
      "Sample node attributes in filtered network:\n",
      "\n",
      "Node ID: dQggEQQH\n",
      "  title: Make ice cream from scratch\n",
      "  description: Ice cream or ice-cream is a frozen dessert usually made from dairy products, suc...\n",
      "  wants_to_do: 3010\n",
      "  have_done: 973\n",
      "  comments: 46 items\n",
      "  tags: 32 items\n",
      "  included_by_our_users: 438\n",
      "  merged_goals: 0 merged goals\n"
     ]
    }
   ],
   "source": [
    "# Build filtered network\n",
    "print(\"Building filtered network...\")\n",
    "print(\"(Only goals with descriptions, merging similar goals)\\n\")\n",
    "\n",
    "G_filtered = nx.Graph()\n",
    "\n",
    "# First, create a mapping of representatives to their merged goals\n",
    "rep_to_merged_goals = defaultdict(list)\n",
    "for gid, rep_id in goal_mapping.items():\n",
    "    if gid != rep_id:  # Only include goals that were merged (not the representative itself)\n",
    "        rep_to_merged_goals[rep_id].append(gid)\n",
    "\n",
    "# Add representative goals as nodes (with all attributes including merged_goals list)\n",
    "for gid in goals_with_descriptions.keys():\n",
    "    # Use representative if this goal was mapped\n",
    "    rep_id = goal_mapping.get(gid, gid)\n",
    "    if rep_id not in G_filtered:\n",
    "        rep_data = goals_with_descriptions[rep_id]\n",
    "        \n",
    "        # Get list of merged goals (empty list if not a representative)\n",
    "        merged_goals_list = rep_to_merged_goals.get(rep_id, [])\n",
    "        \n",
    "        G_filtered.add_node(rep_id, \n",
    "                           title=rep_data['title'],\n",
    "                           description=rep_data['description'],\n",
    "                           wants_to_do=rep_data['wants_to_do'],\n",
    "                           have_done=rep_data['have_done'],\n",
    "                           comments=rep_data['comments'],\n",
    "                           tags=rep_data['tags'],\n",
    "                           included_by_our_users=included_by_our_users.get(rep_id, 0),\n",
    "                           merged_goals=merged_goals_list)\n",
    "\n",
    "print(f\"Added merged_goals attribute to all nodes\")\n",
    "print(f\"  Representatives (with merged goals): {sum(1 for n in G_filtered.nodes() if len(G_filtered.nodes[n]['merged_goals']) > 0):,}\")\n",
    "print(f\"  Non-representatives (empty list): {sum(1 for n in G_filtered.nodes() if len(G_filtered.nodes[n]['merged_goals']) == 0):,}\")\n",
    "\n",
    "# Build edges\n",
    "edge_counter_filtered = Counter()\n",
    "\n",
    "for username, goals_list in users_data.items():\n",
    "    user_goal_ids = [item['id'] for item in goals_list if 'id' in item]\n",
    "    \n",
    "    # Filter to goals with descriptions and map to representatives\n",
    "    user_goal_ids_filtered = []\n",
    "    for gid in user_goal_ids:\n",
    "        if gid in goals_with_descriptions:\n",
    "            rep_id = goal_mapping.get(gid, gid)\n",
    "            user_goal_ids_filtered.append(rep_id)\n",
    "    \n",
    "    # Remove duplicates (if multiple goals map to same representative)\n",
    "    user_goal_ids_filtered = list(set(user_goal_ids_filtered))\n",
    "    \n",
    "    # Create edges\n",
    "    for i, goal_i in enumerate(user_goal_ids_filtered):\n",
    "        for goal_j in user_goal_ids_filtered[i+1:]:\n",
    "            edge = tuple(sorted([goal_i, goal_j]))\n",
    "            edge_counter_filtered[edge] += 1\n",
    "\n",
    "# Add edges\n",
    "for (g1, g2), weight in edge_counter_filtered.items():\n",
    "    if g1 in G_filtered and g2 in G_filtered:\n",
    "        G_filtered.add_edge(g1, g2, weight=weight)\n",
    "\n",
    "# Calculate statistics\n",
    "num_nodes_filtered = G_filtered.number_of_nodes()\n",
    "num_edges_filtered = G_filtered.number_of_edges()\n",
    "density_filtered = nx.density(G_filtered)\n",
    "\n",
    "print(\"\\nFiltered & merged network statistics:\")\n",
    "print(f\"  Nodes: {num_nodes_filtered:,}\")\n",
    "print(f\"  Edges: {num_edges_filtered:,}\")\n",
    "print(f\"  Density: {density_filtered:.8f}\")\n",
    "print(f\"  Average degree: {2*num_edges_filtered/num_nodes_filtered:.2f}\")\n",
    "\n",
    "# Connected components\n",
    "num_components_filtered = nx.number_connected_components(G_filtered)\n",
    "if num_components_filtered > 0:\n",
    "    largest_cc_filtered = max(nx.connected_components(G_filtered), key=len)\n",
    "    print(f\"\\n  Connected components: {num_components_filtered:,}\")\n",
    "    print(f\"  Largest component: {len(largest_cc_filtered):,} nodes ({100*len(largest_cc_filtered)/num_nodes_filtered:.1f}%)\")\n",
    "\n",
    "# Comparison with original\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON: ORIGINAL vs FILTERED & MERGED\")\n",
    "print(\"\\nComparison: Original vs Filtered & Merged\")\n",
    "print(f\"{'Metric':<25} {'Original':<20} {'Filtered & Merged':<20} {'Change':<20}\")\n",
    "\n",
    "node_change = num_nodes_filtered - original_num_nodes\n",
    "edge_change = num_edges_filtered - original_num_edges\n",
    "density_change = density_filtered - original_density\n",
    "\n",
    "print(f\"{'Nodes':<25} {original_num_nodes:<20,} {num_nodes_filtered:<20,} {node_change:>+,} ({100*node_change/original_num_nodes:+.1f}%)\")\n",
    "print(f\"{'Edges':<25} {original_num_edges:<20,} {num_edges_filtered:<20,} {edge_change:>+,} ({100*edge_change/original_num_edges:+.1f}%)\")\n",
    "print(f\"{'Density':<25} {original_density:<20.8f} {density_filtered:<20.8f} {density_change:>+.8f} ({100*density_change/original_density:+.1f}%)\")\n",
    "\n",
    "# Show sample node attributes\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE NODE ATTRIBUTES IN FILTERED NETWORK\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nSample node attributes in filtered network:\")\n",
    "sample_node = list(G_filtered.nodes())[0]\n",
    "print(f\"\\nNode ID: {sample_node}\")\n",
    "for attr, value in G_filtered.nodes[sample_node].items():\n",
    "    if attr in ['comments', 'tags']:\n",
    "        print(f\"  {attr}: {len(value)} items\")\n",
    "    elif attr == 'description':\n",
    "        print(f\"  {attr}: {value[:80]}...\" if len(value) > 80 else f\"  {attr}: {value}\")\n",
    "    elif attr == 'merged_goals':\n",
    "        print(f\"  {attr}: {len(value)} merged goals\")\n",
    "        if len(value) > 0:\n",
    "            print(f\"    First few: {value[:3]}\")\n",
    "    else:\n",
    "        print(f\"  {attr}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83a5ab12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sanity check - merged_goals attribute:\n",
      "  Nodes with merged goals (list size > 0): 283\n",
      "  Nodes without merged goals (empty list): 2,607\n",
      "  Total nodes: 2,890\n",
      "  Percentage with merges: 9.8%\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: Count nodes with merged_goals list size > 0\n",
    "nodes_with_merges = sum(1 for n in G_filtered.nodes() if len(G_filtered.nodes[n]['merged_goals']) > 0)\n",
    "nodes_without_merges = sum(1 for n in G_filtered.nodes() if len(G_filtered.nodes[n]['merged_goals']) == 0)\n",
    "\n",
    "print(\"\\nSanity check - merged_goals attribute:\")\n",
    "print(f\"  Nodes with merged goals (list size > 0): {nodes_with_merges:,}\")\n",
    "print(f\"  Nodes without merged goals (empty list): {nodes_without_merges:,}\")\n",
    "print(f\"  Total nodes: {G_filtered.number_of_nodes():,}\")\n",
    "print(f\"  Percentage with merges: {100*nodes_with_merges/G_filtered.number_of_nodes():.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f4e8c",
   "metadata": {},
   "source": [
    "Calculate and display the number of isolated nodes in the filtered network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dd9d61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Isolated nodes in filtered network: 25 (0.9%)\n"
     ]
    }
   ],
   "source": [
    "# Show number of isolated nodes\n",
    "num_isolated = len(list(nx.isolates(G_filtered)))\n",
    "print(f\"\\n  Isolated nodes in filtered network: {num_isolated:,} ({100*num_isolated/num_nodes_filtered:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de6dcc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SAMPLE NODE ATTRIBUTES IN FILTERED NETWORK\n",
      "\n",
      "Sample node attributes in filtered network:\n",
      "\n",
      "Node ID: dQggEQQH\n",
      "  title: Make ice cream from scratch\n",
      "  description: Ice cream or ice-cream is a frozen dessert usually made from dairy products, suc...\n",
      "  wants_to_do: 3010\n",
      "  have_done: 973\n",
      "  comments: 46 items\n",
      "  tags: 32 items\n",
      "  included_by_our_users: 438\n",
      "  merged_goals: 0 merged goals\n"
     ]
    }
   ],
   "source": [
    "# show all attributes of one sample node\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE NODE ATTRIBUTES IN FILTERED NETWORK\")\n",
    "\n",
    "print(\"\\nSample node attributes in filtered network:\")\n",
    "sample_node = list(G_filtered.nodes())[0]\n",
    "print(f\"\\nNode ID: {sample_node}\")\n",
    "for attr, value in G_filtered.nodes[sample_node].items():\n",
    "    if attr in ['comments', 'tags']:\n",
    "        print(f\"  {attr}: {len(value)} items\")\n",
    "    elif attr == 'description':\n",
    "        print(f\"  {attr}: {value[:80]}...\" if len(value) > 80 else f\"  {attr}: {value}\")\n",
    "    elif attr == 'merged_goals':\n",
    "        print(f\"  {attr}: {len(value)} merged goals\")\n",
    "        if len(value) > 0:\n",
    "            print(f\"    First few: {value[:3]}\")\n",
    "    else:\n",
    "        print(f\"  {attr}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0b2b58",
   "metadata": {},
   "source": [
    "Export the filtered network to a pickle file for use in subsequent analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2908d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network exported successfully\n",
      "  Nodes: 2,890\n",
      "  Edges: 219,130\n",
      "\n",
      "Node attributes preserved:\n",
      "  - title\n",
      "  - description\n",
      "  - wants_to_do\n",
      "  - have_done\n",
      "  - comments\n",
      "  - tags\n",
      "  - included_by_our_users\n",
      "  - merged_goals\n"
     ]
    }
   ],
   "source": [
    "# Export filtered network to pickle file\n",
    "import pickle\n",
    "\n",
    "output_pickle = '../Networks/Prior Network Versions/b1_network.pkl'\n",
    "with open(output_pickle, 'wb') as f:\n",
    "    pickle.dump(G_filtered, f)\n",
    "\n",
    "print(f\"Network exported successfully\")\n",
    "print(f\"  Nodes: {G_filtered.number_of_nodes():,}\")\n",
    "print(f\"  Edges: {G_filtered.number_of_edges():,}\")\n",
    "print(f\"\\nNode attributes preserved:\")\n",
    "sample_node = list(G_filtered.nodes())[0]\n",
    "for attr in G_filtered.nodes[sample_node].keys():\n",
    "    print(f\"  - {attr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb20fabc",
   "metadata": {},
   "source": [
    "# Part II: Network and Language Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149a040c",
   "metadata": {},
   "source": [
    "This part of the code uses the previously created network. It runs independently from the previous workflow, such that it can be accessed without having to run the entire pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40e1dfc",
   "metadata": {},
   "source": [
    "Load the previously saved network and display its basic properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "432d6c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded network from ../Networks/Prior Network Versions/b1_network.pkl:\n",
      "  Nodes: 2,890\n",
      "  Edges: 219,130\n",
      "\n",
      "Sample node attributes for node ID 'dQggEQQH':\n",
      "  title: Make ice cream from scratch\n",
      "  description: Ice cream or ice-cream is a frozen dessert usually made from dairy products, such as milk and cream, and often combined with fruits or other ingredients and flavours. Most varieties contain sugar, although some are made with other sweeteners. In some cases, artificial flavourings and colourings are used in addition to (or in replacement of) the natural ingredients.\n",
      "  wants_to_do: 3010\n",
      "  have_done: 973\n",
      "  comments: ['We made ice cream using a friends ice cream maker.  We adjusted a plain vanilla recipe by adding a flavour essence Mermaid Magic and sprinkles near the end.  While we were impatient and ate this as soon as it got to soft-serve consistency, it was still amazingly good.', '06/26/2022-Made a quart of French Vanilla', 'Got the machineVanillaLemon iceTomato sorbet StrawberryCoffee', 'Basil-lime icecream without an ice creammaker :-)', 'Marbled chocolate ice cream slice. Made without an ice cream maker. Just thickened cream, condensed milk and some Flake and Maltesers.', 'in 3rd grade i made icecream', 'Frozen vegan banana ice cream! Simple and healthy. Cashew and cacao is also quite perfect!!', \"I made banana nice cream!! I've made it a few times now, it's amazing. All you need is bananas, vanilla essence, and a blender/food processor. That's it. I can't remember exactly when I did make it but I'm pretty sure the first time was in April.\", 'Vanilla coconut icecream', 'Made coffee ice cream!', 'made snow ice in February 2014', 'Dairy free pear ice cream with cinnamon!', \"I've made healthy popsicles with avocado, cacao and dade syrup\", 'Kokosijs (glutenvrij) gemaakt voor Bas Sollie op 10-02-2014', \"I took a theoretical ice-cream making class. It just made it sound hard! I'm interested in the custard approach but as someone who's not much good at baking it was unfortunate to hear how similar this will be. The samples were amazing though.\", 'Did this with snow and made \"snow cream\" from scratch with Sam!', 'I made my first Homemade Ice cream. I made vanilla as I figured it would be best to stick to a simple recipe before risking the cost of ingredients for a harder one. I did not let it mix long enough; I was impatient, however it turn out great after it firmed up in the refrigerator! Kids have been enjoying homemade ice cream 100% no chemical good ingredients for the last couple days. Thank you for the great Christmas present, Rhonda!!', 'Got an ice cream machine for my birthday 2013, made milk chocolate ice cream!', 'Rhonda gave me an old fashioned ice cream maker for Christmas! Will make some for our next card party! Whoop!', 'Nov 03/13 - homemade chocolate ice cream. Next, coffee!', 'vanillachocolate strawberry', 'August 7/13 made vanilla and maple ice cream.  So easy, yet impressive.  Lessons learned...use higher fat milk, not 1%.  Tomorrow going to teach people how to make it!', 'July 26/13 - Bought an ice cream maker!', '7/25at work with Maddie', 'Mango ice cream! Recipe from Tsing Tao Daily.', 'Peanutbutter Chocelate Icecream for Mothers day', 'I made Gwyneth Paltrow\\'s Banana \"Ice Cream\" It doesnt have much (fake) milk so it tastes mostly like banana. Nice, and certainly very different. Not quite ice cream.http://www.self.com/fooddiet/recipes/2013/04/banana-ice-cream-roasted-almonds', \"Made Elderflower Sherbert, but I want to make Lavender Ice Cream, so I'll mark it off when that is accomplished.\", 'Ice cream maker on its way!', 'Yum Chocolate IceCream', 'July 2012!', \"I tried another method. It wasn't that much like ice cream but it actually was more solid after I left it on the fridge and everyone but me liked it so I'm counting it as done. Not properly I bet but done.\", '11 Sept 2012 - Failed to make ice cream with method one, will try again tomorrow, maybe with a different one.', 'July 12 - Strawberry Ice cream made :)', 'Made orange ice cream - was ok but think the egg had cooked slightly. Might try cooking cinnamon ice cream another time.', \"May 18, 2012S'more Ice Cream at my house\", 'Do something with a bit of flare, like chocolate covered strawberry ice cream.', \"Steph's?\", 'Made gelato and sorbet!', 'Made Baileys ice cream from scratch - 19/1/12 :)', 'Made AMAZING strawberry ice cream. YUM.', 'Made ice cream with Jackson one hot summer day.All the hard work paid off!', 'Peach ice cream at the beach June 2011', 'Made strawberry pavlova ripple. And I actually succeeded :O :D', 'January 2012', 'I now have an ice cream machine! Wooo :D']\n",
      "  tags: ['Food', 'Recipe', 'Chocolate', 'Fruit', 'Cooking', 'Foodie', 'Homemade', 'Summer', 'Dessert', 'Delicious', 'Sweet Treats', 'Sweet', 'Kitchen', 'Indulgence', 'Butter', 'Ingredients', 'Sugar', 'Culinary', 'Eggs', 'Vanilla', 'Refreshing', 'Whipped Cream', 'Sweets', 'Milk', 'Creamy', 'Treat', 'Yummy', 'Indulgent', 'Dairy', 'Gelato', 'Toppings', 'Rich']\n",
      "  included_by_our_users: 438\n",
      "  merged_goals: []\n"
     ]
    }
   ],
   "source": [
    "# Read in pkl file and show all attributes\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import fasttext\n",
    "import warnings\n",
    "\n",
    "pickle_file = '../Networks/Prior Network Versions/b1_network.pkl'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    G_loaded = pickle.load(f)\n",
    "print(f\"\\nLoaded network from {pickle_file}:\")\n",
    "print(f\"  Nodes: {G_loaded.number_of_nodes():,}\")\n",
    "print(f\"  Edges: {G_loaded.number_of_edges():,}\")\n",
    "sample_node = next(iter(G_loaded.nodes()))\n",
    "print(f\"\\nSample node attributes for node ID '{sample_node}':\")\n",
    "for attr, value in G_loaded.nodes[sample_node].items():\n",
    "    print(f\"  {attr}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baef3ac",
   "metadata": {},
   "source": [
    "Analyze the connectivity of the loaded network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f051628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of connected components in loaded network: 28\n",
      "Size of largest connected component: 2,860 nodes\n"
     ]
    }
   ],
   "source": [
    "# Show amount of connected components\n",
    "num_components_loaded = nx.number_connected_components(G_loaded)\n",
    "print(f\"\\nNumber of connected components in loaded network: {num_components_loaded:,}\")\n",
    "\n",
    "# Length of largest connected component\n",
    "largest_cc_loaded = max(nx.connected_components(G_loaded), key=len)\n",
    "print(f\"Size of largest connected component: {len(largest_cc_loaded):,} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1442d39d",
   "metadata": {},
   "source": [
    "## 10. Language Detection on Network Goals\n",
    "Detect the language of each goal in the filtered network using fastText."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9174979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goals in filtered network: 2,890\n",
      "Prepared 2,890 texts for language detection\n",
      "\n",
      "Text length statistics:\n",
      "  Mean: 485 characters\n",
      "  Median: 474 characters\n",
      "  Max: 2,317 characters\n",
      "  Min: 69 characters\n"
     ]
    }
   ],
   "source": [
    "# Get goals from the filtered network\n",
    "network_goal_ids = list(G_loaded.nodes())\n",
    "print(f\"Goals in filtered network: {len(network_goal_ids):,}\")\n",
    "\n",
    "# Prepare text for language detection\n",
    "goal_combined_texts_network = []\n",
    "for gid in network_goal_ids:\n",
    "    title = G_loaded.nodes[gid].get('title', '')\n",
    "    desc = G_loaded.nodes[gid].get('description', '')\n",
    "    \n",
    "    # Combine title and description\n",
    "    combined = f\"{title}. {desc}\" if desc else title\n",
    "    goal_combined_texts_network.append(combined.strip())\n",
    "\n",
    "print(f\"Prepared {len(goal_combined_texts_network):,} texts for language detection\")\n",
    "\n",
    "# Text statistics\n",
    "text_lengths = [len(t) for t in goal_combined_texts_network]\n",
    "print(f\"\\nText length statistics:\")\n",
    "print(f\"  Mean: {np.mean(text_lengths):.0f} characters\")\n",
    "print(f\"  Median: {np.median(text_lengths):.0f} characters\")\n",
    "print(f\"  Max: {np.max(text_lengths):,} characters\")\n",
    "print(f\"  Min: {np.min(text_lengths):,} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d29b1a",
   "metadata": {},
   "source": [
    "Run language detection using fastText model (most accurate for short texts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc4994d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fastText language detection model...\n",
      "Model loaded\n",
      "\n",
      "Detecting language for 2,890 texts...\n",
      "(Using fasttext - most accurate for short texts)\n",
      "\n",
      "\n",
      "Language detection complete\n",
      "  Total texts: 2,890\n",
      "  Unique languages: 1\n",
      "\n",
      "Top 10 languages detected:\n",
      "  en            2,890 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Loading fastText language detection model...\")\n",
    "model_path = '../Data/Embeddings, Similarity and Language Detection/lid.176.bin'\n",
    "ft_model = fasttext.load_model(model_path)\n",
    "print(\"Model loaded\\n\")\n",
    "\n",
    "print(f\"Detecting language for {len(goal_combined_texts_network):,} texts...\")\n",
    "print(\"(Using fasttext - most accurate for short texts)\\n\")\n",
    "\n",
    "languages_network = []\n",
    "language_scores_network = []\n",
    "\n",
    "for i, text in enumerate(goal_combined_texts_network):\n",
    "    if i % 10000 == 0 and i > 0:\n",
    "        print(f\"  Processed {i:,} / {len(goal_combined_texts_network):,} texts...\")\n",
    "    \n",
    "    try:\n",
    "        # Predict language\n",
    "        predictions = ft_model.predict(text.replace('\\n', ' '), k=1)\n",
    "        lang = predictions[0][0].replace('__label__', '')\n",
    "        score = predictions[1][0]\n",
    "        \n",
    "        languages_network.append(lang)\n",
    "        language_scores_network.append(score)\n",
    "    except:\n",
    "        languages_network.append('unknown')\n",
    "        language_scores_network.append(0.0)\n",
    "\n",
    "print(f\"\\nLanguage detection complete\")\n",
    "print(f\"  Total texts: {len(languages_network):,}\")\n",
    "print(f\"  Unique languages: {len(set(languages_network))}\")\n",
    "\n",
    "# Count language distribution\n",
    "lang_counts_network = Counter(languages_network)\n",
    "\n",
    "print(f\"\\nTop 10 languages detected:\")\n",
    "for lang, count in lang_counts_network.most_common(10):\n",
    "    percentage = 100 * count / len(languages_network)\n",
    "    print(f\"  {lang:<10} {count:>8,} ({percentage:>5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0636ed",
   "metadata": {},
   "source": [
    "Add language information to the network nodes and export to Excel for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefb523c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added language attributes to network nodes\n",
      "  Columns: ['title', 'description', 'wants_to_do', 'have_done', 'comments', 'tags', 'included_by_our_users', 'merged_goals', 'language', 'language_score']\n",
      "  Rows: 2,890\n"
     ]
    }
   ],
   "source": [
    "# Add language attributes to the network nodes\n",
    "for i, gid in enumerate(network_goal_ids):\n",
    "    G_loaded.nodes[gid]['language'] = languages_network[i]\n",
    "    G_loaded.nodes[gid]['language_score'] = language_scores_network[i]\n",
    "\n",
    "print(\"Added language attributes to network nodes\")\n",
    "\n",
    "# Export node attributes to Excel\n",
    "df_nodes = pd.DataFrame.from_dict(dict(G_loaded.nodes(data=True)), orient='index')\n",
    "df_nodes.to_excel('../Data/Validation/b1_network_nodes.xlsx')\n",
    "print(f\"  Columns: {list(df_nodes.columns)}\")\n",
    "print(f\"  Rows: {len(df_nodes):,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
